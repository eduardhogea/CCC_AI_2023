{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "def merge_images(img1, img2):\n",
    "    cloud_pixel = [255, 255, 255]\n",
    "    merged = np.where(img1 == cloud_pixel, img2, img1)\n",
    "    return merged\n",
    "\n",
    "def get_centroid(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        cx, cy = 0, 0\n",
    "    return cx, cy\n",
    "\n",
    "def extract_positions_and_draw_circles(img, img_path):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find all contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    min_area = 0.001 * img.shape[0] * img.shape[1]\n",
    "    filtered_contours = [contour for contour in contours if cv2.contourArea(contour) > min_area]\n",
    "    sorted_contours = sorted(filtered_contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    if len(sorted_contours) < 6:\n",
    "        print(f\"Unexpected number of contours: {len(sorted_contours)}\")\n",
    "        return []\n",
    "\n",
    "    animal_contours = sorted_contours[1:6]\n",
    "    positions = []\n",
    "    for contour in animal_contours:\n",
    "        cx, cy = get_centroid(contour)\n",
    "        positions.append((cx, cy))\n",
    "        cv2.circle(img, (cx, cy), 20, (0, 255, 0), 2)\n",
    "    modified_img_path = img_path.replace(\"_sample0.png\", \"_marked.png\")\n",
    "    cv2.imwrite(modified_img_path, img)\n",
    "\n",
    "    return positions\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(1000):\n",
    "    img_path1 = f\"level_05/test_data/field{i:03d}_sample0.png\"\n",
    "    img_path2 = f\"level_05/test_data/field{i:03d}_sample1.png\"\n",
    "    img1 = np.asarray(Image.open(img_path1).convert('RGB'))\n",
    "    img2 = np.asarray(Image.open(img_path2).convert('RGB'))\n",
    "    merged_img = merge_images(img1, img2)\n",
    "    positions = extract_positions_and_draw_circles(merged_img, img_path1)\n",
    "\n",
    "    flattened_positions = [coord for position in positions for coord in position]\n",
    "    predictions.append(flattened_positions)\n",
    "\n",
    "with open('predictions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
